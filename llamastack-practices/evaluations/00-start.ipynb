{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opik\n",
    "\n",
    "ITERATION_SUMMARY_PROMPT = opik.Prompt(\n",
    "    name=\"Iteration Summary Prompt\",\n",
    "    prompt=\"\"\"\n",
    "Document: {{document}}\n",
    "Current summary: {{current_summary}}\n",
    "Instruction to focus on: {{instruction}}\n",
    "\n",
    "Generate a concise, entity-dense, and highly technical summary from the provided Document that specifically addresses the given Instruction.\n",
    "\n",
    "Guidelines:\n",
    "- Make every word count: If there is a current summary re-write it to improve flow, density and conciseness.\n",
    "- Remove uninformative phrases like \"the article discusses\".\n",
    "- The summary should become highly dense and concise yet self-contained, e.g. , easily understood without the Document.\n",
    "- Make sure that the summary specifically addresses the given Instruction\n",
    "\"\"\".rstrip().lstrip(),\n",
    ")\n",
    "\n",
    "FINAL_SUMMARY_PROMPT = opik.Prompt(\n",
    "    name=\"Final Summary Prompt\",\n",
    "    prompt=\"\"\"\n",
    "Given this summary: {{current_summary}}\n",
    "And this instruction to focus on: {{instruction}}\n",
    "Create an extremely dense, final summary that captures all key technical information in the most concise form possible, while specifically addressing the given instruction.\n",
    "\"\"\".rstrip().lstrip(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"Chain of Density Summarization\" project at http://trainingvm:5173/api/v1/session/redirect/projects/?trace_id=0195c557-16df-7c3f-a1b0-cdae48442e2a&path=aHR0cDovL3RyYWluaW5ndm06NTE3My9hcGkv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI transforms industries by enhancing capabilities: in healthcare, it improves\n",
      "disease diagnosis, outcome prediction, and personalized treatment; in finance,\n",
      "it enhances fraud detection, algorithmic trading, and risk management; in\n",
      "education, it enables personalized learning, adaptive testing, and content\n",
      "generation. However, its integration raises ethical challenges, including data\n",
      "privacy concerns, algorithmic bias, and workforce displacement, necessitating\n",
      "careful examination.\n"
     ]
    }
   ],
   "source": [
    "from opik.integrations.openai import track_openai\n",
    "from openai import OpenAI\n",
    "import opik\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Use a dedicated quickstart endpoint, replace with your own OpenAI API Key in your own code\n",
    "openai_client = track_openai(\n",
    "    OpenAI()\n",
    ")\n",
    "\n",
    "\n",
    "@opik.track\n",
    "def summarize_current_summary(\n",
    "    document: str,\n",
    "    instruction: str,\n",
    "    current_summary: str,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "):\n",
    "    prompt = ITERATION_SUMMARY_PROMPT.format(\n",
    "        document=document, current_summary=current_summary, instruction=instruction\n",
    "    )\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model, max_tokens=4096, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "@opik.track\n",
    "def iterative_density_summarization(\n",
    "    document: str,\n",
    "    instruction: str,\n",
    "    density_iterations: int,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "):\n",
    "    summary = \"\"\n",
    "    for iteration in range(1, density_iterations + 1):\n",
    "        summary = summarize_current_summary(document, instruction, summary, model)\n",
    "    return summary\n",
    "\n",
    "\n",
    "@opik.track\n",
    "def final_summary(instruction: str, current_summary: str, model: str = \"gpt-4o-mini\"):\n",
    "    prompt = FINAL_SUMMARY_PROMPT.format(\n",
    "        current_summary=current_summary, instruction=instruction\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        openai_client.chat.completions.create(\n",
    "            model=model, max_tokens=4096, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )\n",
    "\n",
    "\n",
    "@opik.track(project_name=\"Chain of Density Summarization\")\n",
    "def chain_of_density_summarization(\n",
    "    document: str,\n",
    "    instruction: str,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    density_iterations: int = 2,\n",
    "):\n",
    "    summary = iterative_density_summarization(\n",
    "        document, instruction, density_iterations, model\n",
    "    )\n",
    "    final_summary_text = final_summary(instruction, summary, model)\n",
    "\n",
    "    return final_summary_text\n",
    "\n",
    "import textwrap\n",
    "\n",
    "document = \"\"\"\n",
    "Artificial intelligence (AI) is transforming industries, revolutionizing healthcare, finance, education, and even creative fields. AI systems\n",
    "today are capable of performing tasks that previously required human intelligence, such as language processing, visual perception, and\n",
    "decision-making. In healthcare, AI assists in diagnosing diseases, predicting patient outcomes, and even developing personalized treatment plans.\n",
    "In finance, it helps in fraud detection, algorithmic trading, and risk management. Education systems leverage AI for personalized learning, adaptive\n",
    "testing, and educational content generation. Despite these advancements, ethical concerns such as data privacy, bias, and the impact of AI on employment\n",
    "remain. The future of AI holds immense potential, but also significant challenges.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"Summarize the main contributions of AI to different industries, and highlight both its potential and associated challenges.\"\n",
    "\n",
    "summary = chain_of_density_summarization(document, instruction)\n",
    "\n",
    "print(\"\\n\".join(textwrap.wrap(summary, width=80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Created a \"arXiv Papers\" dataset at http://trainingvm:5173/api/v1/session/redirect/datasets/?dataset_id=0195c557-82b4-7e1e-bae2-53059d493d28&path=aHR0cDovL3RyYWluaW5ndm06NTE3My9hcGkv.\n"
     ]
    }
   ],
   "source": [
    "import opik\n",
    "\n",
    "dataset_items = [\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2301.00234\",\n",
    "        \"title\": \"A Survey on In-context Learning\",\n",
    "        \"instruction\": \"Summarize the key findings on the impact of prompt engineering in in-context learning.\",\n",
    "    },\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2301.03728\",\n",
    "        \"title\": \"Scaling Laws for Generative Mixed-Modal Language Models\",\n",
    "        \"instruction\": \"How do scaling laws apply to generative mixed-modal models according to the paper?\",\n",
    "    },\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2308.10792\",\n",
    "        \"title\": \"Instruction Tuning for Large Language Models: A Survey\",\n",
    "        \"instruction\": \"What are the major challenges in instruction tuning for large language models identified in the paper?\",\n",
    "    },\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2302.08575\",\n",
    "        \"title\": \"Foundation Models in Natural Language Processing: A Survey\",\n",
    "        \"instruction\": \"Explain the role of foundation models in the current natural language processing landscape.\",\n",
    "    },\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2306.13398\",\n",
    "        \"title\": \"Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey\",\n",
    "        \"instruction\": \"What are the cutting edge techniques used in multi-modal pre-training models?\",\n",
    "    },\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2103.07492\",\n",
    "        \"title\": \"Continual Learning in Neural Networks: An Empirical Evaluation\",\n",
    "        \"instruction\": \"What are the main challenges of continual learning for neural networks according to the paper?\",\n",
    "    },\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2304.00685v2\",\n",
    "        \"title\": \"Vision-Language Models for Vision Tasks: A Survey\",\n",
    "        \"instruction\": \"What are the most widely used vision-language models?\",\n",
    "    },\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2303.08774\",\n",
    "        \"title\": \"GPT-4 Technical Report\",\n",
    "        \"instruction\": \"What are the main differences between GPT-4 and GPT-3.5?\",\n",
    "    },\n",
    "    {\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/2406.04744\",\n",
    "        \"title\": \"CRAG -- Comprehensive RAG Benchmark\",\n",
    "        \"instruction\": \"What was the approach to experimenting with different data mixtures?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "client = opik.Opik()\n",
    "DATASET_NAME = \"arXiv Papers\"\n",
    "dataset = client.get_or_create_dataset(name=DATASET_NAME)\n",
    "dataset.insert(dataset_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik.evaluation.metrics import base_metric, score_result\n",
    "import json\n",
    "\n",
    "# We will define the response format so the output has the correct schema. You can also use structured outputs with Pydantic models for this.\n",
    "json_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"summary_evaluation_schema\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"relevance\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"score\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 1,\n",
    "                            \"maximum\": 5,\n",
    "                            \"description\": \"Score between 1-5 for how well the summary addresses the instruction\",\n",
    "                        },\n",
    "                        \"explanation\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Brief explanation of the relevance score\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"score\", \"explanation\"],\n",
    "                },\n",
    "                \"conciseness\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"score\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 1,\n",
    "                            \"maximum\": 5,\n",
    "                            \"description\": \"Score between 1-5 for how concise the summary is while retaining key information\",\n",
    "                        },\n",
    "                        \"explanation\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Brief explanation of the conciseness score\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"score\", \"explanation\"],\n",
    "                },\n",
    "                \"technical_accuracy\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"score\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 1,\n",
    "                            \"maximum\": 5,\n",
    "                            \"description\": \"Score between 1-5 for how accurately the summary conveys technical details\",\n",
    "                        },\n",
    "                        \"explanation\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Brief explanation of the technical accuracy score\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"score\", \"explanation\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"relevance\", \"conciseness\", \"technical_accuracy\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# Custom Metric: One template/prompt to extract 4 scores/results\n",
    "class EvaluateSummary(base_metric.BaseMetric):\n",
    "    # Constructor\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    def score(\n",
    "        self, summary: str, instruction: str, model: str = \"gpt-4o-mini\", **kwargs\n",
    "    ):\n",
    "        prompt = f\"\"\"\n",
    "            Summary: {summary}\n",
    "            Instruction: {instruction}\n",
    "\n",
    "            Evaluate the summary based on the following criteria:\n",
    "            1. Relevance (1-5): How well does the summary address the given instruction?\n",
    "            2. Conciseness (1-5): How concise is the summary while retaining key information?\n",
    "            3. Technical Accuracy (1-5): How accurately does the summary convey technical details?\n",
    "\n",
    "            Your response MUST be in the following JSON format:\n",
    "            {{\n",
    "                \"relevance\": {{\n",
    "                    \"score\": <int>,\n",
    "                    \"explanation\": \"<string>\"\n",
    "                }},\n",
    "            \"conciseness\": {{\n",
    "                \"score\": <int>,\n",
    "                \"explanation\": \"<string>\"\n",
    "                }},\n",
    "            \"technical_accuracy\": {{\n",
    "                \"score\": <int>,\n",
    "                \"explanation\": \"<string>\"\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            Ensure that the scores are integers between 1 and 5, and that the explanations are concise.\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            max_tokens=1000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format=json_schema,\n",
    "        )\n",
    "\n",
    "        eval_dict = json.loads(response.choices[0].message.content)\n",
    "\n",
    "        return [\n",
    "            score_result.ScoreResult(\n",
    "                name=\"summary_relevance\",\n",
    "                value=eval_dict[\"relevance\"][\"score\"],\n",
    "                reason=eval_dict[\"relevance\"][\"explanation\"],\n",
    "            ),\n",
    "            score_result.ScoreResult(\n",
    "                name=\"summary_conciseness\",\n",
    "                value=eval_dict[\"conciseness\"][\"score\"],\n",
    "                reason=eval_dict[\"conciseness\"][\"explanation\"],\n",
    "            ),\n",
    "            score_result.ScoreResult(\n",
    "                name=\"summary_technical_accuracy\",\n",
    "                value=eval_dict[\"technical_accuracy\"][\"score\"],\n",
    "                reason=eval_dict[\"technical_accuracy\"][\"explanation\"],\n",
    "            ),\n",
    "            score_result.ScoreResult(\n",
    "                name=\"summary_average_score\",\n",
    "                value=round(sum(eval_dict[k][\"score\"] for k in eval_dict) / 3, 2),\n",
    "                reason=\"The average of the 3 summary evaluation metrics\",\n",
    "            ),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "from PyPDF2 import PdfReader\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "# Load and extract text from PDFs\n",
    "@opik.track\n",
    "def load_pdf(pdf_url: str) -> str:\n",
    "    # Download the PDF\n",
    "    response = requests.get(pdf_url)\n",
    "    pdf_file = io.BytesIO(response.content)\n",
    "\n",
    "    # Read the PDF\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "    # Extract text from all pages\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    # Truncate the text to 100000 characters as this is the maximum supported by OpenAI\n",
    "    text = text[:100000]\n",
    "    return text\n",
    "\n",
    "\n",
    "def evaluation_task(x: Dict):\n",
    "    text = load_pdf(x[\"pdf_url\"])\n",
    "    instruction = x[\"instruction\"]\n",
    "    model = MODEL\n",
    "    density_iterations = DENSITY_ITERATIONS\n",
    "\n",
    "    result = chain_of_density_summarization(\n",
    "        document=text,\n",
    "        instruction=instruction,\n",
    "        model=model,\n",
    "        density_iterations=density_iterations,\n",
    "    )\n",
    "\n",
    "    return {\"summary\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 9/9 [01:02<00:00,  6.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ arXiv Papers (9 samples) ───────────────╮\n",
       "│                                          │\n",
       "│ <span style=\"font-weight: bold\">Total time:       </span> 00:01:02              │\n",
       "│ <span style=\"font-weight: bold\">Number of samples:</span> 9                     │\n",
       "│                                          │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">summary_relevance: 4.4444 (avg)</span>          │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">summary_conciseness: 3.8889 (avg)</span>        │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">summary_technical_accuracy: 4.8889 (avg)</span> │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">summary_average_score: 4.4100 (avg)</span>      │\n",
       "│                                          │\n",
       "╰──────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ arXiv Papers (9 samples) ───────────────╮\n",
       "│                                          │\n",
       "│ \u001b[1mTotal time:       \u001b[0m 00:01:02              │\n",
       "│ \u001b[1mNumber of samples:\u001b[0m 9                     │\n",
       "│                                          │\n",
       "│ \u001b[1;32msummary_relevance: 4.4444 (avg)\u001b[0m          │\n",
       "│ \u001b[1;32msummary_conciseness: 3.8889 (avg)\u001b[0m        │\n",
       "│ \u001b[1;32msummary_technical_accuracy: 4.8889 (avg)\u001b[0m │\n",
       "│ \u001b[1;32msummary_average_score: 4.4100 (avg)\u001b[0m      │\n",
       "│                                          │\n",
       "╰──────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Uploading results to Opik \u001b[33m...\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">View the results <a href=\"http://trainingvm:5173/api/v1/session/redirect/experiments/?experiment_id=0195c558-8e39-74fd-b18e-e2924163c61e&dataset_id=0195c557-82b4-7e1e-bae2-53059d493d28&path=aHR0cDovL3RyYWluaW5ndm06NTE3My9hcGkv\" target=\"_blank\">in your Opik dashboard</a>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "View the results \u001b]8;id=85614;http://trainingvm:5173/api/v1/session/redirect/experiments/?experiment_id=0195c558-8e39-74fd-b18e-e2924163c61e&dataset_id=0195c557-82b4-7e1e-bae2-53059d493d28&path=aHR0cDovL3RyYWluaW5ndm06NTE3My9hcGkv\u001b\\in your Opik dashboard\u001b]8;;\u001b\\.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from opik.evaluation import evaluate\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "DENSITY_ITERATIONS = 2\n",
    "\n",
    "experiment_config = {\n",
    "    \"iteration_summary_prompt\": ITERATION_SUMMARY_PROMPT,\n",
    "    \"final_summary_prompt\": FINAL_SUMMARY_PROMPT,\n",
    "    \"model\": MODEL,\n",
    "    \"density_iterations\": DENSITY_ITERATIONS,\n",
    "}\n",
    "\n",
    "res = evaluate(\n",
    "    dataset=dataset,\n",
    "    experiment_config=experiment_config,\n",
    "    task=evaluation_task,\n",
    "    scoring_metrics=[EvaluateSummary(name=\"summary-metrics\")],\n",
    "    prompt=ITERATION_SUMMARY_PROMPT,\n",
    "    project_name=\"Chain of Density Summarization\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opik\n",
    "\n",
    "ITERATION_SUMMARY_PROMPT = opik.Prompt(\n",
    "    name=\"Iteration Summary Prompt\",\n",
    "    prompt=\"\"\"Document: {{document}}\n",
    "Current summary: {{current_summary}}\n",
    "Instruction to focus on: {{instruction}}\n",
    "\n",
    "Generate a concise, entity-dense, and highly technical summary from the provided Document that specifically addresses the given Instruction.\n",
    "\n",
    "Guidelines:\n",
    "1. **Maximize Clarity and Density**: Revise the current summary to enhance flow, density, and conciseness.\n",
    "2. **Eliminate Redundant Language**: Avoid uninformative phrases such as \"the article discusses.\"\n",
    "3. **Ensure Self-Containment**: The summary should be dense and concise, easily understandable without referring back to the document.\n",
    "4. **Align with Instruction**: Make sure the summary specifically addresses the given instruction.\n",
    "\n",
    "\"\"\".rstrip().lstrip(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 9/9 [00:46<00:00,  5.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ arXiv Papers (9 samples) ───────────────╮\n",
       "│                                          │\n",
       "│ <span style=\"font-weight: bold\">Total time:       </span> 00:00:46              │\n",
       "│ <span style=\"font-weight: bold\">Number of samples:</span> 9                     │\n",
       "│                                          │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">summary_relevance: 4.6667 (avg)</span>          │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">summary_conciseness: 3.8889 (avg)</span>        │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">summary_technical_accuracy: 4.8889 (avg)</span> │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">summary_average_score: 4.4844 (avg)</span>      │\n",
       "│                                          │\n",
       "╰──────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ arXiv Papers (9 samples) ───────────────╮\n",
       "│                                          │\n",
       "│ \u001b[1mTotal time:       \u001b[0m 00:00:46              │\n",
       "│ \u001b[1mNumber of samples:\u001b[0m 9                     │\n",
       "│                                          │\n",
       "│ \u001b[1;32msummary_relevance: 4.6667 (avg)\u001b[0m          │\n",
       "│ \u001b[1;32msummary_conciseness: 3.8889 (avg)\u001b[0m        │\n",
       "│ \u001b[1;32msummary_technical_accuracy: 4.8889 (avg)\u001b[0m │\n",
       "│ \u001b[1;32msummary_average_score: 4.4844 (avg)\u001b[0m      │\n",
       "│                                          │\n",
       "╰──────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Uploading results to Opik \u001b[33m...\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">View the results <a href=\"http://trainingvm:5173/api/v1/session/redirect/experiments/?experiment_id=0195c559-846e-7e69-bc14-7a9ff879e162&dataset_id=0195c557-82b4-7e1e-bae2-53059d493d28&path=aHR0cDovL3RyYWluaW5ndm06NTE3My9hcGkv\" target=\"_blank\">in your Opik dashboard</a>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "View the results \u001b]8;id=998667;http://trainingvm:5173/api/v1/session/redirect/experiments/?experiment_id=0195c559-846e-7e69-bc14-7a9ff879e162&dataset_id=0195c557-82b4-7e1e-bae2-53059d493d28&path=aHR0cDovL3RyYWluaW5ndm06NTE3My9hcGkv\u001b\\in your Opik dashboard\u001b]8;;\u001b\\.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from opik.evaluation import evaluate\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "DENSITY_ITERATIONS = 2\n",
    "\n",
    "experiment_config = {\n",
    "    \"iteration_summary_prompt\": ITERATION_SUMMARY_PROMPT,\n",
    "    \"final_summary_prompt\": FINAL_SUMMARY_PROMPT,\n",
    "    \"model\": MODEL,\n",
    "    \"density_iterations\": DENSITY_ITERATIONS,\n",
    "}\n",
    "\n",
    "res = evaluate(\n",
    "    dataset=dataset,\n",
    "    experiment_config=experiment_config,\n",
    "    task=evaluation_task,\n",
    "    scoring_metrics=[EvaluateSummary(name=\"summary-metrics\")],\n",
    "    prompt=ITERATION_SUMMARY_PROMPT,\n",
    "    project_name=\"Chain of Density Summarization\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
