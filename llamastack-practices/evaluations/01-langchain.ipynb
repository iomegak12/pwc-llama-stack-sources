{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the relevant data\n",
    "import os\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://github.com/lerocha/chinook-database/raw/master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite\"\n",
    "filename = \"./data/chinook/Chinook_Sqlite.sqlite\"\n",
    "\n",
    "folder = os.path.dirname(filename)\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    response = requests.get(url)\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Chinook database downloaded\")\n",
    "\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik.integrations.openai import track_openai\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "os.environ[\"OPIK_PROJECT_NAME\"] = \"langchain-integration-demo\"\n",
    "client = OpenAI()\n",
    "\n",
    "openai_client = track_openai(client)\n",
    "\n",
    "prompt = \"\"\"\n",
    "Create 20 different example questions a user might ask based on the Chinook Database.\n",
    "\n",
    "These questions should be complex and require the model to think. They should include complex joins and window functions to answer.\n",
    "\n",
    "Return the response as a json object with a \"result\" key and an array of strings with the question.\n",
    "\"\"\"\n",
    "\n",
    "completion = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the synthetic dataset\n",
    "import opik\n",
    "\n",
    "synthetic_questions = json.loads(completion.choices[0].message.content)[\"result\"]\n",
    "\n",
    "client = opik.Opik()\n",
    "\n",
    "dataset = client.get_or_create_dataset(name=\"synthetic_questions\")\n",
    "dataset.insert([{\"question\": question} for question in synthetic_questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use langchain to create a SQL query to answer the question\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from opik.integrations.langchain import OpikTracer\n",
    "\n",
    "opik_tracer = OpikTracer(tags=[\"simple_chain\"])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "chain = create_sql_query_chain(llm, db).with_config({\"callbacks\": [opik_tracer]})\n",
    "response = chain.invoke({\"question\": \"How many employees are there ?\"})\n",
    "response\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik import Opik, track\n",
    "from opik.evaluation import evaluate\n",
    "from opik.evaluation.metrics import base_metric, score_result\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class ValidSQLQuery(base_metric.BaseMetric):\n",
    "    def __init__(self, name: str, db: Any):\n",
    "        self.name = name\n",
    "        self.db = db\n",
    "\n",
    "    def score(self, output: str, **ignored_kwargs: Any):\n",
    "        # Add you logic here\n",
    "\n",
    "        try:\n",
    "            db.run(output)\n",
    "            return score_result.ScoreResult(\n",
    "                name=self.name, value=1, reason=\"Query ran successfully\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return score_result.ScoreResult(name=self.name, value=0, reason=str(e))\n",
    "\n",
    "\n",
    "valid_sql_query = ValidSQLQuery(name=\"valid_sql_query\", db=db)\n",
    "\n",
    "client = Opik()\n",
    "dataset = client.get_dataset(\"synthetic_questions\")\n",
    "\n",
    "\n",
    "@track()\n",
    "def llm_chain(input: str) -> str:\n",
    "    response = chain.invoke({\"question\": input})\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def evaluation_task(item):\n",
    "    response = llm_chain(item[\"question\"])\n",
    "\n",
    "    return {\"output\": response}\n",
    "\n",
    "\n",
    "res = evaluate(\n",
    "    experiment_name=\"SQL question answering\",\n",
    "    dataset=dataset,\n",
    "    task=evaluation_task,\n",
    "    scoring_metrics=[valid_sql_query],\n",
    "    nb_samples=20,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
