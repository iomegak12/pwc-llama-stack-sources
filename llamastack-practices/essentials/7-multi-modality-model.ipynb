{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Modality Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from llama_stack_client import LlamaStackClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "LLAMA_STACK_API_TOGETHER_URL = os.environ[\"TOGETHER_URL\"]\n",
    "TOGETHER_API_KEY = os.environ[\"TOGETHER_API_KEY\"]\n",
    "LLAMA32_11B_VISION_INSTRUCT = \"Llama3.2-11B-Vision-Instruct\"\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=LLAMA_STACK_API_TOGETHER_URL,\n",
    "    provider_data={\n",
    "        \"together_api_key\": TOGETHER_API_KEY\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=\"meta-llama/Llama-3.2-11B-Vision-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "from termcolor import cprint\n",
    "from llama_stack_client.lib.inference.event_logger import EventLogger\n",
    "\n",
    "\n",
    "def encode_image_to_data_url(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Encode an image file to a data URL.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the image file\n",
    "\n",
    "    Returns:\n",
    "        str: Data URL string\n",
    "    \"\"\"\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    if mime_type is None:\n",
    "        raise ValueError(\"Could not determine MIME type of the file\")\n",
    "\n",
    "    with open(file_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    return f\"data:{mime_type};base64,{encoded_string}\"\n",
    "\n",
    "\n",
    "async def process_image(client, image_path: str, stream: bool = True):\n",
    "    \"\"\"\n",
    "    Process an image through the LlamaStack Vision API.\n",
    "\n",
    "    Args:\n",
    "        client (LlamaStackClient): Initialized client\n",
    "        image_path (str): Path to image file\n",
    "        stream (bool): Whether to stream the response\n",
    "    \"\"\"\n",
    "    data_url = encode_image_to_data_url(image_path)\n",
    "\n",
    "    # message = [\n",
    "    #     {\n",
    "    #         \"role\": \"user\",\n",
    "    #         \"content\": [\n",
    "    #             {\n",
    "    #                 \"type\": \"image_url\",\n",
    "    #                 \"image_url\": {\n",
    "    #                     \"url\": data_url\n",
    "    #                 }\n",
    "    #             },\n",
    "    #             {\n",
    "    #                 \"type\": \"text\",\n",
    "    #                 \"text\": \"describe the image as specific as possible\"\n",
    "    #             }\n",
    "    #         ]\n",
    "    #     }\n",
    "    # ]\n",
    "\n",
    "    message = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "                {\"type\": \"image\", \"image\": {\"url\": {\"uri\": data_url}}},\n",
    "                {\"type\": \"text\", \"text\": \"describe the image as specific as possible\"},\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "    cprint(\"User> Sending image for analysis...\", \"green\")\n",
    "    response = client.inference.chat_completion(\n",
    "        messages=message,\n",
    "        model_id=MODEL_NAME,\n",
    "        stream=stream,\n",
    "    )\n",
    "\n",
    "    if not stream:\n",
    "        cprint(f\"> Response: {response}\", \"cyan\")\n",
    "    else:\n",
    "        async for log in EventLogger().log(response):\n",
    "            log.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUser> Sending image for analysis...\u001b[0m\n",
      "\u001b[36m> Response: ChatCompletionResponse(completion_message=CompletionMessage(content='The image depicts a serene scene of four alpacas standing in a grassy field, with a wooden fence in the background. The alpacas are positioned in a natural and relaxed manner, with one standing in front of the others, facing the camera. The two alpacas in the foreground are brown, while the two in the background are tan. The alpaca in the foreground is the largest, and it appears to be a male, as it has a larger body and a more prominent set of testicles. The alpaca in the middle is a female, as it has a smaller body and no visible testicles. The two alpacas in the background are also females, as they have smaller bodies and no visible testicles.\\n\\nThe alpacas are standing on a grassy field, with a wooden fence behind them. The fence is made of horizontal logs and has a rustic appearance. In the background, there is a hill or mountain, which adds depth and context to the scene. The overall atmosphere of the image is one of tranquility and serenity, with the alpacas appearing relaxed and content in their natural surroundings.', role='assistant', stop_reason='end_of_turn', tool_calls=[]), logprobs=None, metrics=None)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "await process_image(client, \"./llama-stock.png\", stream=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
